<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Case Study: Long-Context Diagnostics and Constraint-Based Mitigation for Gemini 2.5 Flash and GPT-4o-mini by Nathan St. Pierre.">
    <meta name="author" content="Nathan St. Pierre">
    <title>Gemini vs GPT-4o-mini Long-Context Study | Nathan St. Pierre</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,600;1,400&family=Montserrat:wght@400;600;700;800&display=swap" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <style>
        :root {
            --primary-brand: #aa784d;
            --dark-text: #2a2a2a;
        }

        body { font-family: 'Lora', serif; color: #444; line-height: 1.7; }
        h1, h2, h3, h4, h5, .nav-link, .btn, .tech-label { font-family: 'Montserrat', sans-serif; }

        .navbar { padding: 1rem 0; box-shadow: 0 2px 15px rgba(0,0,0,0.05); background: rgba(255, 255, 255, 0.98); }
        .navbar-brand { font-weight: 800; color: var(--dark-text); }
        .nav-link { font-weight: 600; color: #555 !important; margin: 0 10px; }
        .nav-link:hover, .nav-link.active { color: var(--primary-brand) !important; }

        .btn-brand {
            background-color: var(--primary-brand);
            border-color: var(--primary-brand);
            color: white;
            padding: 10px 25px;
            font-weight: 600;
            border-radius: 6px;
            transition: all 0.3s ease;
        }
        .btn-brand:hover { background-color: #8a603d; color: white; transform: translateY(-2px); }

        .project-header {
            background: linear-gradient(to right, #f8f9fa, #e9ecef);
            padding: 80px 0;
            border-bottom: 1px solid #ddd;
        }

        .tech-stack-item {
            background: #fff;
            padding: 10px 15px;
            border-radius: 5px;
            border: 1px solid #eee;
            margin-bottom: 10px;
            display: inline-block;
            font-family: 'Montserrat', sans-serif;
            font-size: 0.9rem;
            font-weight: 600;
        }

        .architecture-step {
            border-left: 3px solid var(--primary-brand);
            padding-left: 20px;
            margin-bottom: 30px;
        }

        .callout {
            border-radius: 6px;
            padding: 1rem 1.25rem;
            background: #fff7f0;
            border-left: 4px solid var(--primary-brand);
            font-size: 0.95rem;
        }

        footer { background-color: var(--dark-text); color: #ddd; padding: 60px 0 30px 0; }
        .footer-link { color: #aaa; text-decoration: none; display: block; margin-bottom: 10px; }
        .footer-link:hover { color: var(--primary-brand); }
    </style>
</head>
<body>

    <nav class="navbar navbar-expand-lg sticky-top">
        <div class="container">
            <a class="navbar-brand" href="index.html">NATHAN ST. PIERRE</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#mainNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="mainNav">
                <ul class="navbar-nav ms-auto align-items-center">
                    <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                    <li class="nav-item"><a class="nav-link active" href="projects.html">Projects</a></li>
                    <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>
                    <li class="nav-item"><a class="nav-link" href="about.html">About Me</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <header class="project-header">
        <div class="container">
            <div class="row align-items-center">
                <div class="col-lg-8">
                    <span class="text-uppercase text-muted fw-bold" style="font-size: 0.9rem; letter-spacing: 1px;">
                        Long-Context Reliability Research
                    </span>
                    <h1 class="fw-bold display-4 mt-2 mb-3">
                        Gemini vs GPT‑4o‑mini: Long‑Context Diagnostics & Mitigation
                    </h1>
                    <p class="lead text-muted">
                        A controlled needle‑in‑a‑haystack study of Gemini 2.5 Flash and GPT‑4o‑mini, focused on position bias,
                        adversarial distractors, and constraint‑based verification layers for safer long‑context retrieval.[file:31][web:67]
                    </p>
                    <div class="mt-4">
                        <a href="https://www.kaggle.com/code/doctorn8/gemini-vs-gpt-4o-mini" target="_blank" class="btn btn-brand btn-lg me-3">
                            <i class="fas fa-rocket me-2"></i>Open Kaggle Notebook
                        </a>
                        <!-- Optional: update with your repo link -->
                        <a href="#" class="btn btn-outline-dark btn-lg">
                            <i class="fab fa-github me-2"></i>View Code
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <section class="py-5">
        <div class="container">
            <div class="row">
                <!-- Main content -->
                <div class="col-lg-8">
                    <h3 class="fw-bold mb-4">Motivation & Research Questions</h3>
                    <p>
                        Long‑context marketing often emphasizes maximum token capacity, but real systems care about whether a model
                        reliably surfaces the one critical fact buried in thousands of tokens.[file:31][web:67]
                        This notebook frames Gemini 2.5 Flash and GPT‑4o‑mini as experimental subjects and asks how accuracy changes
                        with evidence position, how fragile they are to realistic distractors, and how much a simple verification layer
                        can mitigate these failure modes without retraining.[file:31]
                    </p>

                    <div class="callout my-4">
                        <strong>Design inspiration:</strong> The study is influenced by “lost in the middle” style evaluations
                        and “when transformers know but don’t tell,” treating long‑context reliability as a behavioral property
                        that can be probed, quantified, and constrained.[file:31][web:67]
                    </div>

                    <h3 class="fw-bold mb-4 mt-5">Needle‑in‑a‑Haystack Probe Generator</h3>
                    <p>
                        At the core of the experiment is a <strong>ContextProbeGenerator</strong> class that builds synthetic
                        “corporate log” contexts containing one true security code (“the needle”) for a specific project ID and a
                        configurable number of fake look‑alike codes as distractors.[file:31]
                        For each probe, it returns the full prompt, the ground‑truth six‑digit code, the target depth, the number of
                        distractors, and an approximate token count.[file:31]
                    </p>

                    <div class="my-4 p-4 bg-light rounded">
                        <h4 class="fw-bold mb-3">
                            <i class="fas fa-layer-group me-2"></i>Probe Construction Pipeline
                        </h4>

                        <div class="architecture-step">
                            <h5 class="fw-bold">1. Needle creation</h5>
                            <p class="mb-0">
                                The generator samples a project ID (for example, PROJ‑X99) and a unique six‑digit security code,
                                then emits a canonical line such as “CRITICAL ALERT PROJECT PROJ‑X99 SECURITY CODE IS 123456.”[file:31]
                            </p>
                        </div>

                        <div class="architecture-step">
                            <h5 class="fw-bold">2. Distractor synthesis</h5>
                            <p class="mb-0">
                                It samples a set of plausible “INFO LOG” entries that contain other project IDs and other six‑digit codes,
                                ensuring the distractors look structurally similar to the true signal.[file:31]
                            </p>
                        </div>

                        <div class="architecture-step">
                            <h5 class="fw-bold">3. Haystack assembly</h5>
                            <p class="mb-0">
                                Filler log sentences are drawn from a fixed list to reach a target context size, distractors are inserted
                                at random positions, and the true needle is inserted at a requested depth percentage (0 = start,
                                0.5 = middle, 1.0 = end).[file:31]
                            </p>
                        </div>

                        <div class="architecture-step">
                            <h5 class="fw-bold">4. Instruction wrapping</h5>
                            <p class="mb-0">
                                Finally, the generator wraps the log data in an instruction block telling the model to return only
                                the six‑digit code in JSON format, such as <code>{"code": "123456"}</code>, which makes parsing
                                and error classification straightforward.[file:31]
                            </p>
                        </div>
                    </div>

                    <h3 class="fw-bold mb-4 mt-5">Models, APIs, and Mock Mode</h3>
                    <p>
                        The notebook uses the official <code>google-generativeai</code> client to query Gemini 2.5 Flash and the
                        OpenAI client to query GPT‑4o‑mini, wrapping both in small helper functions that take a prompt string and
                        return text.[file:31][web:60][web:63]
                        Environment variables or Kaggle secrets supply API keys when available; if keys are missing, the functions
                        fall back to a mock mode that simulates realistic failure patterns so the full pipeline still runs.[file:31]
                    </p>

                    <p>
                        In mock mode, Gemini’s accuracy is degraded more aggressively under heavy noise, while GPT‑4o‑mini is given
                        a specific weakness at mid‑context depths, letting you see the intended “lost in the middle” curves even
                        without paid API access.[file:31][web:67]
                        When real keys are present, the same harness collects genuine outputs and logs latency for each call, enabling
                        side‑by‑side comparisons.[file:31]
                    </p>

                    <h3 class="fw-bold mb-4 mt-5">Error Taxonomy & Evaluation Loop</h3>
                    <p>
                        A dedicated <code>is_correct</code> function and error classifier label each model response as
                        <em>correct</em>, <em>hallucination</em>, or <em>format error</em>.[file:31]
                        The classifier first attempts to parse JSON, then falls back to regex to find any six‑digit sequence,
                        distinguishing between wrong codes (hallucinations) and outputs that never yield a valid code at all
                        (format errors).[file:31]
                    </p>

                    <p>
                        The main <code>run_comparison_grid</code> function sweeps across depths and noise levels, generating
                        paired probes and sending them to both models, then records accuracy, latency, context length, and
                        error type for each run.[file:31]
                        The resulting dataframe feeds into aggregate metrics and Seaborn plots that visualize position bias
                        (“lost in the middle”) and noise robustness curves.[file:31][web:67]
                    </p>

                    <div class="callout my-4">
                        <strong>Behavioral example:</strong> The notebook includes runs where a model confidently returns a
                        well‑formed but incorrect code when multiple fake codes are present, which the error taxonomy flags
                        as hallucinations rather than simple misses.[file:31]
                    </div>

                    <h3 class="fw-bold mb-4 mt-5">Constraint‑Based Verification Layer</h3>
                    <p>
                        To explore mitigation without retraining, the notebook implements a <strong>verification layer</strong>
                        that only accepts a predicted code if it can be re‑found in the original context near the target project ID.[file:31]
                        The verification function searches for the project tag in the haystack, then checks whether the candidate
                        code appears within a configurable window of characters around that anchor.[file:31]
                    </p>

                    <p>
                        By running a small experiment on a fixed depth and distractor setting, the notebook compares raw accuracy
                        to “constrained accuracy” — the fraction of answers that are both correct and verifiable under this rule.[file:31]
                        It also reports how many hallucinations are downgraded to “no answer” (verification failure), illustrating
                        how a simple structural constraint can reduce the risk of fabricated codes.[file:31]
                    </p>

                    <h3 class="fw-bold mb-4 mt-5">Analysis & Visualization</h3>
                    <p>
                        The analysis layer groups results by model and depth to plot position‑bias curves, then by model and
                        number of distractors to show how each system degrades under adversarial noise.[file:31][web:67]
                        Additional plots compare accuracy distributions and latency side‑by‑side, supporting an empirical,
                        behavior‑first story rather than a one‑off anecdote.[file:31]
                    </p>

                    <p>
                        A small logistic regression (using scikit‑learn) is set up to model success probability as a function
                        of depth, distractor count, context length, and model identity, turning qualitative impressions into
                        interpretable coefficients.[file:31]
                        The notebook also computes simple win‑rates — how often Gemini vs GPT‑4o‑mini wins on the same probe —
                        to summarize relative performance under different conditions.[file:31]
                    </p>

                    <h3 class="fw-bold mb-4 mt-5">Key Findings & Implications</h3>
                    <p>
                        The study surfaces classic long‑context failure modes: both models show sensitivity to evidence position,
                        especially in the middle of the haystack, and both can be pushed into structured hallucinations by
                        realistic fake codes.[file:31][web:67]
                        Crucially, the error taxonomy reveals that many failures are not simple “did not find it” cases but
                        confident, wrong extractions or malformed outputs, which map directly to safety concerns in real
                        retrieval‑augmented systems.[file:31]
                    </p>

                    <p>
                        The constraint‑based verification layer demonstrates that a large share of hallucinated codes can be
                        filtered out by checking for local textual support, trading some coverage for significantly better
                        precision.[file:31]
                        For practitioners, the notebook functions as a reusable harness: drop in any pair of models, run the
                        grid, and get concrete behavioral metrics and mitigation levers for long‑context deployments.[file:31]
                    </p>
                </div>

                <!-- Sidebar -->
                <div class="col-lg-4">
                    <div class="card border-0 shadow-sm p-4 bg-light mb-4">
                        <h5 class="fw-bold mb-3">Tech Stack</h5>
                        <div>
                            <span class="tech-stack-item"><i class="fas fa-code me-2"></i>Python</span>
                            <span class="tech-stack-item"><i class="fas fa-brain me-2"></i>Gemini 2.5 Flash</span>
                            <span class="tech-stack-item"><i class="fas fa-robot me-2"></i>GPT‑4o‑mini</span>
                            <span class="tech-stack-item"><i class="fas fa-square-root-alt me-2"></i>NumPy</span>
                            <span class="tech-stack-item"><i class="fas fa-table me-2"></i>Pandas</span>
                            <span class="tech-stack-item"><i class="fas fa-chart-line me-2"></i>Matplotlib & Seaborn</span>
                            <span class="tech-stack-item"><i class="fas fa-project-diagram me-2"></i>scikit‑learn</span>
                        </div>

                        <hr class="my-4">

                        <h5 class="fw-bold mb-3">Experiment Components</h5>
                        <ul class="list-unstyled">
                            <li class="mb-2">
                                <i class="fas fa-flask me-2 text-muted"></i>
                                Needle‑in‑a‑haystack probe generator with depth and distractor controls.[file:31]
                            </li>
                            <li class="mb-2">
                                <i class="fas fa-code-branch me-2 text-muted"></i>
                                Paired evaluation harness for Gemini 2.5 Flash and GPT‑4o‑mini, with mock‑mode support for offline runs.[file:31]
                            </li>
                            <li class="mb-2">
                                <i class="fas fa-bug-slash me-2 text-muted"></i>
                                Error taxonomy and parsing logic for correct, hallucination, and format‑error responses.[file:31]
                            </li>
                            <li class="mb-2">
                                <i class="fas fa-shield-alt me-2 text-muted"></i>
                                Constraint‑based verification layer that checks whether predicted codes are locally supported by the context.[file:31]
                            </li>
                            <li class="mb-2">
                                <i class="fas fa-chart-area me-2 text-muted"></i>
                                Aggregation and plotting of position‑bias and noise‑robustness curves for each model.[file:31][web:67]
                            </li>
                        </ul>
                    </div>

                    <div class="card border-0 shadow-sm p-4">
                        <h5 class="fw-bold mb-3">Role & Outcomes</h5>
                        <p class="mb-2">
                            I designed and implemented the full experimental pipeline, including probe generation, API integration,
                            error taxonomy, constraint layer, and visual analytics.[file:31]
                        </p>
                        <p class="mb-0">
                            The result is a reusable, model‑agnostic framework for diagnosing long‑context reliability and
                            validating mitigation strategies before deploying LLMs into production RAG and safety‑critical
                            retrieval workflows.[file:31][web:67]
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-4 mb-4">
                    <h5 class="footer-heading">Nathan St. Pierre</h5>
                    <p>AI Solutions Architect & Researcher.</p>
                </div>
                <div class="col-md-4 mb-4">
                    <h5 class="footer-heading">Quick Links</h5>
                    <a href="index.html" class="footer-link">Home</a>
                    <a href="projects.html" class="footer-link">Projects</a>
                    <a href="https://www.kaggle.com/code/doctorn8/gemini-vs-gpt-4o-mini" target="_blank" class="footer-link">Kaggle Notebook</a>
                </div>
                <div class="col-md-4 mb-4">
                    <h5 class="footer-heading">Connect</h5>
                    <a href="mailto:nathan.stpierre@gmail.com" class="footer-link">
                        <i class="fas fa-envelope me-2"></i>Contact
                    </a>
                    <a href="https://linkedin.com/in/doctorn8" class="footer-link">
                        <i class="fab fa-linkedin me-2"></i>LinkedIn</a>
                </div>
            </div>
            <hr class="my-4" style="border-color: #555;">
            <div class="text-center">
                <p class="mb-0">&copy; 2025 Nathan St. Pierre.</p>
            </div>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
